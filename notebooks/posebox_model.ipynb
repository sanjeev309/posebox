{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output = 8\n",
    "input_shape = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_FOLDER = '/home/sanjeev309/Projects/posebox/resized_frames'\n",
    "ANNOTATION_FILE = '/home/sanjeev309/Projects/posebox/annotation_formatted.csv'\n",
    "OUTPUT = '/home/sanjeev309/Projects/posebox/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = OUTPUT + \"/ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise empty numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((0,512,512,3), dtype=np.int8)\n",
    "target = np.empty((0,8), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read annotation file, fetch image, normalise image and array, compose data and target arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(ANNOTATION_FILE,'r') as csv_file:\n",
    "    \n",
    "    reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    \n",
    "    for row in reader:\n",
    "        \n",
    "        print(row)\n",
    "        \n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            image_path = os.path.join(IMAGES_FOLDER, row[0])\n",
    "            image = cv2.imread(image_path)/ 255\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            \n",
    "            points = row[1]\n",
    "            dimen = (float)(row[2])\n",
    "            \n",
    "            p = points.strip('][').split(', ')\n",
    "            \n",
    "            \n",
    "            p = np.array(p, dtype=np.int)\n",
    "            p = np.divide(p, dimen)\n",
    "            p = np.expand_dims(p, axis=0)\n",
    "            \n",
    "            if image is not None:\n",
    "                data = np.vstack((data, image))\n",
    "                target = np.vstack((target, p))\n",
    "            \n",
    "            line_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data and target synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[arr]\n",
    "target = target[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(OUTPUT,'data.npy'), data)\n",
    "np.save(os.path.join(OUTPUT,'target.npy'), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(OUTPUT,'data.npy'))\n",
    "target = np.load(os.path.join(OUTPUT,'target.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[0: int(num_samples * TRAIN_RATIO) - 1]\n",
    "y_train = target[0: int(num_samples * TRAIN_RATIO) - 1]\n",
    "\n",
    "X_test = data[int(num_samples * TRAIN_RATIO): num_samples - 1]\n",
    "y_test = target[int(num_samples * TRAIN_RATIO): num_samples - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = keras.applications.MobileNetV2(input_shape=(127, 127,3),\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    print(base_model.summary())\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(3, (2,2),activation='relu'),\n",
    "        layers.MaxPool2D((2,2)),\n",
    "        layers.Conv2D(3,(2,2), activation='relu'),\n",
    "        layers.MaxPool2D((2,2)),\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(32),\n",
    "        layers.Dense(16),\n",
    "        layers.Dense(num_output, activation=\"sigmoid\"),\n",
    "\n",
    "    ])\n",
    "    optimizer = keras.optimizers.SGD(0.01)\n",
    "\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + '/' + name\n",
    "                   for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print('Restoring from', latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print('Creating a new model')\n",
    "    return build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 5 epochs.\n",
    "    # We include the training loss in the folder name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + '/ckpt-loss={loss:.2f}',\n",
    "        # save_freq=4)\n",
    "        period=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_history = model.fit(data, target, batch_size=batch_size, validation_split= 0.2, epochs=5000,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
